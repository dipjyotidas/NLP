{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author : Dipjyoti Das (https://www.linkedin.com/in/dipjyotidas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script is used to Train classifiers on the dataset and all the classifers are saved as pickle files.\n",
    "\n",
    "### The pickled classfiers are used in the sentiment_analysis.py file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664\n",
      "Original Naive Bayes Algo accuracy percent: 73.64457831325302\n",
      "Most Informative Features\n",
      "               wonderful = True              pos : neg    =     21.8 : 1.0\n",
      "              engrossing = True              pos : neg    =     19.7 : 1.0\n",
      "                 generic = True              neg : pos    =     16.9 : 1.0\n",
      "                mediocre = True              neg : pos    =     16.9 : 1.0\n",
      "               inventive = True              pos : neg    =     15.7 : 1.0\n",
      "                 routine = True              neg : pos    =     14.9 : 1.0\n",
      "                    flat = True              neg : pos    =     14.9 : 1.0\n",
      "              refreshing = True              pos : neg    =     14.4 : 1.0\n",
      "                  boring = True              neg : pos    =     13.8 : 1.0\n",
      "                    warm = True              pos : neg    =     13.1 : 1.0\n",
      "                intimate = True              pos : neg    =     11.7 : 1.0\n",
      "               realistic = True              pos : neg    =     11.7 : 1.0\n",
      "                   stale = True              neg : pos    =     11.6 : 1.0\n",
      "                mindless = True              neg : pos    =     11.6 : 1.0\n",
      "                delicate = True              pos : neg    =     11.0 : 1.0\n",
      "MNB_classifier accuracy percent: 74.24698795180723\n",
      "BernoulliNB_classifier accuracy percent: 74.3975903614458\n",
      "LogisticRegression_classifier accuracy percent: 73.49397590361446\n",
      "LinearSVC_classifier accuracy percent: 72.13855421686746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dipjyoti\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier accuracy percent: 71.83734939759037\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "#from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "        \n",
    "        \n",
    "        \n",
    "short_pos = open(\"data/positive.txt\",\"r\").read()\n",
    "short_neg = open(\"data/negative.txt\",\"r\").read()\n",
    "\n",
    "\n",
    "# using POS -parts of speech tag - allow only specific words\n",
    "#pos - tuple- word, parts of speech\n",
    "\n",
    "all_words = []\n",
    "documents = []\n",
    "\n",
    "#  j is adject, r is adverb, and v is verb\n",
    "#allowed_word_types = [\"J\",\"R\",\"V\"]\n",
    "allowed_word_types = [\"J\"] # allowing only Adjectives\n",
    "\n",
    "for p in short_pos.split('\\n'):\n",
    "    documents.append((p, \"pos\") )\n",
    "    words = word_tokenize(p)\n",
    "    pos = nltk.pos_tag(words)\n",
    "    for w in pos:\n",
    "        if w[1][0] in allowed_word_types: # w - tuple, not getting Nouns, commas\n",
    "            all_words.append(w[0].lower())\n",
    "\n",
    "            \n",
    "for p in short_neg.split('\\n'):\n",
    "    documents.append((p, \"neg\"))\n",
    "    words = word_tokenize(p)\n",
    "    pos = nltk.pos_tag(words)\n",
    "    for w in pos:\n",
    "        if w[1][0] in allowed_word_types:\n",
    "            all_words.append(w[0].lower())\n",
    "\n",
    "\n",
    "# pickle and store documents\n",
    "# pickled algos - folder created to store all the pickled objects :\n",
    "\n",
    "\n",
    "save_documents = open(\"pickled_algos/documents.pickle\", \"wb\")\n",
    "pickle.dump(documents, save_documents)\n",
    "save_documents.close()\n",
    "\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "\n",
    "word_features = list(all_words.keys())[:5000]\n",
    "\n",
    "# pickle and store word features\n",
    "save_word_features = open(\"pickled_algos/word_features5k.pickle\",\"wb\")\n",
    "pickle.dump(word_features, save_word_features)\n",
    "save_word_features.close()\n",
    "\n",
    "\n",
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "# Pickle and store - featuresets :\n",
    "\n",
    "save_featuresets = open(\"pickled_algos/featuresets.pickle\", \"wb\")\n",
    "pickle.dump(featuresets, save_featuresets)\n",
    "save_featuresets.close()\n",
    "\n",
    "random.shuffle(featuresets)\n",
    "print(len(featuresets))\n",
    "\n",
    "\n",
    "# Train and Test set:\n",
    "\n",
    "\n",
    "testing_set = featuresets[10000:]\n",
    "training_set = featuresets[:10000]\n",
    "\n",
    "\n",
    "## List of Classifiers :\n",
    "\n",
    "## Naive Bayes classifier:\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "## pickle and store - Naive Bayes classifier\n",
    "save_classifier = open(\"pickled_algos/originalnaivebayes5k.pickle\",\"wb\")\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "\n",
    "## MNB classifier :\n",
    "\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "\n",
    "# pickle and store MNB classifier:\n",
    "\n",
    "save_classifier = open(\"pickled_algos/MNB_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(MNB_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "## BernoulliNB classifier:\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "#pickle and store BernoulliNB classifier:\n",
    "\n",
    "save_classifier = open(\"pickled_algos/BernoulliNB_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(BernoulliNB_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "\n",
    "## Logistic Regression classifier:\n",
    "\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "#pickle and store Logistic Regression classifier:\n",
    "\n",
    "save_classifier = open(\"pickled_algos/LogisticRegression_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(LogisticRegression_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "\n",
    "## LinearSVC classifier\n",
    "\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "\n",
    "# pickle and store LinearSVC classifier:\n",
    "\n",
    "save_classifier = open(\"pickled_algos/LinearSVC_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(LinearSVC_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "## SGDC classifier:\n",
    "\n",
    "SGDC_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDC_classifier.train(training_set)\n",
    "print(\"SGDClassifier accuracy percent:\",nltk.classify.accuracy(SGDC_classifier, testing_set)*100)\n",
    "\n",
    "# pickle and store SGDC classifier:\n",
    "\n",
    "save_classifier = open(\"pickled_algos/SGDC_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(SGDC_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "\n",
    "## Can't pickle the Voted Classifier - class of its own\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run upto this cell one time. The sentiment analysis module uses the saved pickle objects and it also has the voting classfier and the sentiment function. The module saved is sentiment_analysis.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After importing the sentiment analysis module :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can use this to check if any sentiment is positive or negative with the confidence level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pos', 1.0)\n",
      "('neg', 1.0)\n"
     ]
    }
   ],
   "source": [
    "import sentiment_analysis as s\n",
    "\n",
    "# referencing the sentiment function of the sentiment_analysis.py script\n",
    "\n",
    "# Example -  Pass through our own positive review\n",
    "print(s.sentiment(\"This movie was awesome! The story was great and performances were amazing, I really liked it!\"))\n",
    "\n",
    "# Example - Pass through a negative review\n",
    "print(s.sentiment(\"This movie was junk. No story at all and acting sucked. Horrible movie, 1/10\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Both are at 100% confidence level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This module can be used to perform live sentiment analysis from Twitter!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
